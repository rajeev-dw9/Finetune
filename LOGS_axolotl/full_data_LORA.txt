[2024-02-07 12:44:55,273] [INFO] [datasets.<module>:58] [PID:76187] PyTorch version 2.1.2 available.
[2024-02-07 12:44:55,321] [INFO] [datasets.<module>:58] [PID:76189] PyTorch version 2.1.2 available.
[2024-02-07 12:44:55,347] [INFO] [datasets.<module>:58] [PID:76188] PyTorch version 2.1.2 available.
[2024-02-07 12:44:55,358] [INFO] [datasets.<module>:58] [PID:76190] PyTorch version 2.1.2 available.
[2024-02-07 12:44:56,043] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-02-07 12:44:56,090] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-02-07 12:44:56,117] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-02-07 12:44:56,126] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-02-07 12:44:56,962] [DEBUG] [axolotl.normalize_config:68] [PID:76187] [RANK:0] bf16 support detected, enabling for this configuration.[39m
[2024-02-07 12:44:57,002] [DEBUG] [axolotl.normalize_config:68] [PID:76189] [RANK:2] bf16 support detected, enabling for this configuration.[39m
[2024-02-07 12:44:57,033] [DEBUG] [axolotl.normalize_config:68] [PID:76188] [RANK:1] bf16 support detected, enabling for this configuration.[39m
[2024-02-07 12:44:57,042] [DEBUG] [axolotl.normalize_config:68] [PID:76190] [RANK:3] bf16 support detected, enabling for this configuration.[39m
[2024-02-07 12:44:57,088] [INFO] [axolotl.normalize_config:170] [PID:76189] [RANK:2] GPU memory usage baseline: 0.000GB (+0.511GB misc)[39m
[2024-02-07 12:44:57,145] [INFO] [axolotl.normalize_config:170] [PID:76187] [RANK:0] GPU memory usage baseline: 0.000GB (+0.511GB misc)[39m
[2024-02-07 12:44:57,146] [INFO] [axolotl.normalize_config:170] [PID:76190] [RANK:3] GPU memory usage baseline: 0.000GB (+0.511GB misc)[39m
[2024-02-07 12:44:57,146] [INFO] [axolotl.normalize_config:170] [PID:76188] [RANK:1] GPU memory usage baseline: 0.000GB (+0.511GB misc)[39m
                                 dP            dP   dP 
                                 88            88   88 
      .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 
      88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 
      88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 
      `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP 
                                                       
                                                       

[2024-02-07 12:44:58,231] [DEBUG] [axolotl.load_tokenizer:241] [PID:76187] [RANK:0] EOS: 2 / </s>[39m
[2024-02-07 12:44:58,231] [DEBUG] [axolotl.load_tokenizer:242] [PID:76187] [RANK:0] BOS: 1 / <s>[39m
[2024-02-07 12:44:58,231] [DEBUG] [axolotl.load_tokenizer:243] [PID:76187] [RANK:0] PAD: 0 / <unk>[39m
[2024-02-07 12:44:58,232] [DEBUG] [axolotl.load_tokenizer:244] [PID:76187] [RANK:0] UNK: 0 / <unk>[39m
[2024-02-07 12:44:58,232] [INFO] [axolotl.load_tokenizer:255] [PID:76187] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.[39m
[2024-02-07 12:44:58,232] [INFO] [axolotl.load_tokenized_prepared_datasets:187] [PID:76187] [RANK:0] Loading prepared dataset from disk at last_run_prepared/562b26c50683b92a3855e02aca772c25...[39m
[2024-02-07 12:44:58,410] [INFO] [axolotl.load_tokenized_prepared_datasets:189] [PID:76187] [RANK:0] Prepared dataset loaded from disk...[39m
[2024-02-07 12:44:58,539] [DEBUG] [axolotl.load_tokenizer:241] [PID:76190] [RANK:3] EOS: 2 / </s>[39m
[2024-02-07 12:44:58,539] [DEBUG] [axolotl.load_tokenizer:242] [PID:76190] [RANK:3] BOS: 1 / <s>[39m
[2024-02-07 12:44:58,539] [DEBUG] [axolotl.load_tokenizer:243] [PID:76190] [RANK:3] PAD: 0 / <unk>[39m
[2024-02-07 12:44:58,539] [DEBUG] [axolotl.load_tokenizer:244] [PID:76190] [RANK:3] UNK: 0 / <unk>[39m
[2024-02-07 12:44:58,539] [INFO] [axolotl.load_tokenizer:255] [PID:76190] [RANK:3] No Chat template selected. Consider adding a chat template for easier inference.[39m
[2024-02-07 12:44:58,544] [DEBUG] [axolotl.load_tokenizer:241] [PID:76189] [RANK:2] EOS: 2 / </s>[39m
[2024-02-07 12:44:58,544] [DEBUG] [axolotl.load_tokenizer:242] [PID:76189] [RANK:2] BOS: 1 / <s>[39m
[2024-02-07 12:44:58,544] [DEBUG] [axolotl.load_tokenizer:241] [PID:76188] [RANK:1] EOS: 2 / </s>[39m
[2024-02-07 12:44:58,544] [DEBUG] [axolotl.load_tokenizer:243] [PID:76189] [RANK:2] PAD: 0 / <unk>[39m
[2024-02-07 12:44:58,544] [DEBUG] [axolotl.load_tokenizer:242] [PID:76188] [RANK:1] BOS: 1 / <s>[39m
[2024-02-07 12:44:58,544] [DEBUG] [axolotl.load_tokenizer:244] [PID:76189] [RANK:2] UNK: 0 / <unk>[39m
[2024-02-07 12:44:58,544] [DEBUG] [axolotl.load_tokenizer:243] [PID:76188] [RANK:1] PAD: 0 / <unk>[39m
[2024-02-07 12:44:58,544] [INFO] [axolotl.load_tokenizer:255] [PID:76189] [RANK:2] No Chat template selected. Consider adding a chat template for easier inference.[39m
[2024-02-07 12:44:58,544] [DEBUG] [axolotl.load_tokenizer:244] [PID:76188] [RANK:1] UNK: 0 / <unk>[39m
[2024-02-07 12:44:58,544] [INFO] [axolotl.load_tokenizer:255] [PID:76188] [RANK:1] No Chat template selected. Consider adding a chat template for easier inference.[39m
[2024-02-07 12:45:01,796] [INFO] [axolotl.load_tokenized_prepared_datasets:187] [PID:76188] [RANK:1] Loading prepared dataset from disk at last_run_prepared/562b26c50683b92a3855e02aca772c25...[39m
[2024-02-07 12:45:01,796] [INFO] [axolotl.load_tokenized_prepared_datasets:187] [PID:76190] [RANK:3] Loading prepared dataset from disk at last_run_prepared/562b26c50683b92a3855e02aca772c25...[39m
[2024-02-07 12:45:01,796] [INFO] [axolotl.load_tokenized_prepared_datasets:187] [PID:76189] [RANK:2] Loading prepared dataset from disk at last_run_prepared/562b26c50683b92a3855e02aca772c25...[39m
[2024-02-07 12:45:01,976] [INFO] [axolotl.load_tokenized_prepared_datasets:189] [PID:76188] [RANK:1] Prepared dataset loaded from disk...[39m
[2024-02-07 12:45:01,980] [INFO] [axolotl.load_tokenized_prepared_datasets:189] [PID:76189] [RANK:2] Prepared dataset loaded from disk...[39m
[2024-02-07 12:45:01,981] [INFO] [axolotl.load_tokenized_prepared_datasets:189] [PID:76190] [RANK:3] Prepared dataset loaded from disk...[39m
[2024-02-07 12:45:06,731] [DEBUG] [axolotl.log:61] [PID:76187] [RANK:0] total_num_tokens: 250740855[39m
[2024-02-07 12:46:15,404] [DEBUG] [axolotl.log:61] [PID:76187] [RANK:0] `total_supervised_tokens: 250740855`[39m
[2024-02-07 12:46:24,941] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76187] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:46:24,941] [DEBUG] [axolotl.log:61] [PID:76187] [RANK:0] data_loader_len: 30299[39m
[2024-02-07 12:46:27,109] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76189] [RANK:2] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:46:27,154] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76188] [RANK:1] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:46:27,488] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76190] [RANK:3] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:46:27,555] [INFO] [axolotl.log:61] [PID:76187] [RANK:0] sample_packing_eff_est across ranks: [0.997978925704956, 0.997978925704956, 0.997978925704956, 0.997978925704956][39m
[2024-02-07 12:46:27,556] [DEBUG] [axolotl.log:61] [PID:76187] [RANK:0] sample_packing_eff_est: 1.0[39m
[2024-02-07 12:46:27,556] [DEBUG] [axolotl.log:61] [PID:76187] [RANK:0] total_num_steps: 15149[39m
[2024-02-07 12:46:27,564] [DEBUG] [axolotl.train.log:61] [PID:76187] [RANK:0] loading tokenizer... NousResearch/Llama-2-7b-chat-hf[39m
[2024-02-07 12:46:27,694] [DEBUG] [axolotl.load_tokenizer:241] [PID:76187] [RANK:0] EOS: 2 / </s>[39m
[2024-02-07 12:46:27,695] [DEBUG] [axolotl.load_tokenizer:242] [PID:76187] [RANK:0] BOS: 1 / <s>[39m
[2024-02-07 12:46:27,695] [DEBUG] [axolotl.load_tokenizer:243] [PID:76187] [RANK:0] PAD: 0 / <unk>[39m
[2024-02-07 12:46:27,695] [DEBUG] [axolotl.load_tokenizer:244] [PID:76187] [RANK:0] UNK: 0 / <unk>[39m
[2024-02-07 12:46:27,695] [INFO] [axolotl.load_tokenizer:255] [PID:76187] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.[39m
[2024-02-07 12:46:27,695] [DEBUG] [axolotl.train.log:61] [PID:76187] [RANK:0] loading model and peft_config...[39m
[2024-02-07 12:46:27,721] [DEBUG] [axolotl.load_tokenizer:241] [PID:76190] [RANK:3] EOS: 2 / </s>[39m
[2024-02-07 12:46:27,721] [DEBUG] [axolotl.load_tokenizer:242] [PID:76190] [RANK:3] BOS: 1 / <s>[39m
[2024-02-07 12:46:27,721] [DEBUG] [axolotl.load_tokenizer:243] [PID:76190] [RANK:3] PAD: 0 / <unk>[39m
[2024-02-07 12:46:27,721] [DEBUG] [axolotl.load_tokenizer:244] [PID:76190] [RANK:3] UNK: 0 / <unk>[39m
[2024-02-07 12:46:27,721] [INFO] [axolotl.load_tokenizer:255] [PID:76190] [RANK:3] No Chat template selected. Consider adding a chat template for easier inference.[39m
[2024-02-07 12:46:27,727] [DEBUG] [axolotl.load_tokenizer:241] [PID:76188] [RANK:1] EOS: 2 / </s>[39m
[2024-02-07 12:46:27,727] [DEBUG] [axolotl.load_tokenizer:242] [PID:76188] [RANK:1] BOS: 1 / <s>[39m
[2024-02-07 12:46:27,727] [DEBUG] [axolotl.load_tokenizer:243] [PID:76188] [RANK:1] PAD: 0 / <unk>[39m
[2024-02-07 12:46:27,727] [DEBUG] [axolotl.load_tokenizer:244] [PID:76188] [RANK:1] UNK: 0 / <unk>[39m
[2024-02-07 12:46:27,727] [INFO] [axolotl.load_tokenizer:255] [PID:76188] [RANK:1] No Chat template selected. Consider adding a chat template for easier inference.[39m
[2024-02-07 12:46:27,772] [INFO] [axolotl.load_model:311] [PID:76187] [RANK:0] patching with flash attention for sample packing[39m
[2024-02-07 12:46:27,772] [INFO] [axolotl.load_model:397] [PID:76187] [RANK:0] patching _expand_mask[39m
[2024-02-07 12:46:27,800] [INFO] [axolotl.load_model:311] [PID:76190] [RANK:3] patching with flash attention for sample packing[39m
[2024-02-07 12:46:27,800] [INFO] [axolotl.load_model:397] [PID:76190] [RANK:3] patching _expand_mask[39m
[2024-02-07 12:46:27,807] [INFO] [axolotl.load_model:311] [PID:76188] [RANK:1] patching with flash attention for sample packing[39m
[2024-02-07 12:46:27,808] [INFO] [axolotl.load_model:397] [PID:76188] [RANK:1] patching _expand_mask[39m
[2024-02-07 12:46:27,876] [DEBUG] [axolotl.load_tokenizer:241] [PID:76189] [RANK:2] EOS: 2 / </s>[39m
[2024-02-07 12:46:27,876] [DEBUG] [axolotl.load_tokenizer:242] [PID:76189] [RANK:2] BOS: 1 / <s>[39m
[2024-02-07 12:46:27,876] [DEBUG] [axolotl.load_tokenizer:243] [PID:76189] [RANK:2] PAD: 0 / <unk>[39m
[2024-02-07 12:46:27,876] [DEBUG] [axolotl.load_tokenizer:244] [PID:76189] [RANK:2] UNK: 0 / <unk>[39m
[2024-02-07 12:46:27,876] [INFO] [axolotl.load_tokenizer:255] [PID:76189] [RANK:2] No Chat template selected. Consider adding a chat template for easier inference.[39m
[2024-02-07 12:46:27,952] [INFO] [axolotl.load_model:311] [PID:76189] [RANK:2] patching with flash attention for sample packing[39m
[2024-02-07 12:46:27,952] [INFO] [axolotl.load_model:397] [PID:76189] [RANK:2] patching _expand_mask[39m
[2024-02-07 12:47:04,953] [INFO] [axolotl.load_model:681] [PID:76187] [RANK:0] GPU memory usage after model load: 7.170GB (+0.004GB cache, +0.918GB misc)[39m
[2024-02-07 12:47:04,954] [INFO] [axolotl.load_model:681] [PID:76190] [RANK:3] GPU memory usage after model load: 7.170GB (+0.004GB cache, +0.918GB misc)[39m
[2024-02-07 12:47:04,955] [INFO] [axolotl.load_model:681] [PID:76189] [RANK:2] GPU memory usage after model load: 7.170GB (+0.004GB cache, +0.918GB misc)[39m
[2024-02-07 12:47:04,955] [INFO] [axolotl.load_model:681] [PID:76188] [RANK:1] GPU memory usage after model load: 7.170GB (+0.004GB cache, +0.918GB misc)[39m
[2024-02-07 12:47:04,959] [INFO] [axolotl.load_model:722] [PID:76187] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training[39m
[2024-02-07 12:47:04,960] [INFO] [axolotl.load_model:722] [PID:76190] [RANK:3] converting PEFT model w/ prepare_model_for_kbit_training[39m
[2024-02-07 12:47:04,961] [INFO] [axolotl.load_model:722] [PID:76189] [RANK:2] converting PEFT model w/ prepare_model_for_kbit_training[39m
[2024-02-07 12:47:04,961] [INFO] [axolotl.load_model:722] [PID:76188] [RANK:1] converting PEFT model w/ prepare_model_for_kbit_training[39m
[2024-02-07 12:47:04,962] [INFO] [axolotl.load_model:731] [PID:76187] [RANK:0] converting modules to torch.bfloat16 for flash attention[39m
[2024-02-07 12:47:04,963] [INFO] [axolotl.load_model:731] [PID:76190] [RANK:3] converting modules to torch.bfloat16 for flash attention[39m
[2024-02-07 12:47:04,964] [INFO] [axolotl.load_model:731] [PID:76188] [RANK:1] converting modules to torch.bfloat16 for flash attention[39m
[2024-02-07 12:47:04,964] [INFO] [axolotl.load_model:731] [PID:76189] [RANK:2] converting modules to torch.bfloat16 for flash attention[39m
[2024-02-07 12:47:04,965] [INFO] [axolotl.load_lora:846] [PID:76187] [RANK:0] found linear modules: ['down_proj', 'q_proj', 'k_proj', 'v_proj', 'gate_proj', 'up_proj', 'o_proj'][39m
[2024-02-07 12:47:04,966] [INFO] [axolotl.load_lora:846] [PID:76190] [RANK:3] found linear modules: ['v_proj', 'k_proj', 'gate_proj', 'down_proj', 'up_proj', 'o_proj', 'q_proj'][39m
[2024-02-07 12:47:04,968] [INFO] [axolotl.load_lora:846] [PID:76188] [RANK:1] found linear modules: ['k_proj', 'v_proj', 'o_proj', 'gate_proj', 'down_proj', 'up_proj', 'q_proj'][39m
[2024-02-07 12:47:04,968] [INFO] [axolotl.load_lora:846] [PID:76189] [RANK:2] found linear modules: ['gate_proj', 'v_proj', 'down_proj', 'up_proj', 'o_proj', 'k_proj', 'q_proj'][39m
trainable params: 79,953,920 || all params: 6,818,377,728 || trainable%: 1.1726237998177387
[2024-02-07 12:47:05,727] [INFO] [axolotl.load_model:771] [PID:76190] [RANK:3] GPU memory usage after adapters: 7.469GB (+0.857GB cache, +0.918GB misc)[39m
trainable params: 79,953,920 || all params: 6,818,377,728 || trainable%: 1.1726237998177387
trainable params: 79,953,920 || all params: 6,818,377,728 || trainable%: 1.1726237998177387
trainable params: 79,953,920 || all params: 6,818,377,728 || trainable%: 1.1726237998177387
[2024-02-07 12:47:05,732] [INFO] [axolotl.load_model:771] [PID:76187] [RANK:0] GPU memory usage after adapters: 7.469GB (+0.857GB cache, +0.918GB misc)[39m
[2024-02-07 12:47:05,732] [INFO] [axolotl.load_model:771] [PID:76189] [RANK:2] GPU memory usage after adapters: 7.469GB (+0.857GB cache, +0.918GB misc)[39m
[2024-02-07 12:47:05,734] [INFO] [axolotl.load_model:771] [PID:76188] [RANK:1] GPU memory usage after adapters: 7.469GB (+0.857GB cache, +0.918GB misc)[39m
[2024-02-07 12:47:05,821] [INFO] [axolotl.train.log:61] [PID:76187] [RANK:0] Pre-saving adapter config to ./lora-out[39m
[2024-02-07 12:47:05,829] [INFO] [axolotl.train.log:61] [PID:76187] [RANK:0] Starting trainer...[39m
[2024-02-07 12:47:11,741] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76187] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:11,744] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76190] [RANK:3] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:11,752] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76189] [RANK:2] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:11,753] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76188] [RANK:1] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:17,273] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76187] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:17,285] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76190] [RANK:3] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:17,290] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76189] [RANK:2] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:17,291] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76188] [RANK:1] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:22,418] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76187] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:22,432] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76190] [RANK:3] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:22,453] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76188] [RANK:1] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:22,454] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76189] [RANK:2] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:28,003] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76187] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:28,008] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76190] [RANK:3] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:28,031] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76189] [RANK:2] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:28,037] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76188] [RANK:1] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:35,361] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76189] [RANK:2] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:35,380] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76188] [RANK:1] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:35,385] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76190] [RANK:3] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:35,444] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76187] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:40,531] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76189] [RANK:2] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:40,548] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76188] [RANK:1] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:40,575] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76190] [RANK:3] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
[2024-02-07 12:47:40,588] [INFO] [axolotl.utils.samplers.multipack._len_est:184] [PID:76187] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 62685213[39m
{'loss': 4.1167, 'learning_rate': 2e-05, 'epoch': 0.0}
