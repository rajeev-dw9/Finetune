{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Project_Files/env_llm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/Project_Files/env_llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1900: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/Project_Files/env_llm/lib/python3.10/site-packages/transformers/modeling_utils.py:2852: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "# Constants\n",
    "MODEL = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "ADAPTER = 'rajeev-dw9/med_llama'\n",
    "HF_TOKEN = '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'\n",
    "\n",
    "# Function to perform inference\n",
    "def generate_answer(model, tokenizer, prompt, max_new_tokens=512):\n",
    "    with torch.no_grad():\n",
    "        output_tensors = model.generate(\n",
    "            input_ids=tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda(),\n",
    "            max_new_tokens=max_new_tokens\n",
    "        )[0]\n",
    "    return tokenizer.decode(output_tensors, skip_special_tokens=True).split('### Answer')[-1]\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL, legacy=False, use_auth_token=HF_TOKEN)\n",
    "\n",
    "# Load base model\n",
    "base_model = LlamaForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    device_map='auto',\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_auth_token=HF_TOKEN,\n",
    ")\n",
    "\n",
    "# Load PEFT adapted model\n",
    "model_A = PeftModel.from_pretrained(\n",
    "    base_model, ADAPTER, torch_dtype=torch.float16, is_trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Answer: \n",
      "Epilepsy is a neurological disorder that affects the brain and is characterized by recurrent seizures. The genetic basis of epilepsy is complex and varied, with multiple genes and mechanisms involved. Here are some of the genes that have been implicated in epilepsy:\n",
      "\n",
      "1. SCN1A - a gene that encodes the sodium channel protein Nav1.1, which is involved in the regulation of action potentials and is associated with familial epilepsy.\n",
      "2. KCNQ2 - a gene that encodes the potassium channel protein Kv7.2, which is involved in the regulation of after-hyperpolarization and is associated with epileptic encephalopathy.\n",
      "3. GRIN1 - a gene that encodes the glutamate receptor ion channel protein GRIN1, which is involved in the regulation of synaptic transmission and is associated with familial epilepsy.\n",
      "4. CACNA1A - a gene that encodes the calcium channel protein CACNA1A, which is involved in the regulation of action potentials and is associated with familial epilepsy.\n",
      "5. DEPDC1 - a gene that encodes the protein DEPDC1, which is involved in the regulation of synaptic plasticity and is associated with epilepsy.\n",
      "6. BDNF - a gene/protein that encodes the brain-derived neurotrophic factor, which is involved in the regulation of synaptic plasticity and is associated with epilepsy.\n",
      "7. HTRA1 - a gene/protein that encodes the heparin binding protein 1, which is involved in the regulation of inflammation and is associated with epilepsy.\n",
      "8. STXBP1 - a gene/protein that encodes the STXBP1, which is involved in the regulation of synaptic transmission and is associated with epilepsy.\n",
      "9. CYP26A1 - a gene/protein that encodes the cytochrome P450 26A1, which is involved in the regulation of gene expression and is associated with epilepsy.\n",
      "10. PPARA - a gene/protein\n",
      "PEFT Adapted Model Answer: \n",
      "Epilepsy is a chronic neurological disorder characterized by recurrent seizures. The disorder is caused by a variety of genetic and non-genetic factors. Here are some genes that have been linked to epilepsy:\n",
      "\n",
      "1. SCN1A - sodium channel gene\n",
      "2. KCNQ2 - potassium channel gene\n",
      "3. GRIN1 - N-methyl-D-aspartate receptor gene\n",
      "4. CACNA1A - calcium channel gene\n",
      "5. DEPDC1 - dystroglycan complex gene\n",
      "6. TCF4 - transcription factor gene\n",
      "7. CTCF - transcription factor gene\n",
      "8. HES1 - transcription factor gene\n",
      "9. KCNQ3 - potassium channel gene\n",
      "10. CYP26A1 - gene/protein\n",
      "\n",
      "Note: This is not an exhaustive list and there are many other genes that have been implicated in epilepsy.\n"
     ]
    }
   ],
   "source": [
    "# Your prompt here\n",
    "prompt = \"\"\"\n",
    "### Instruction\n",
    "What is epilipsy? List genes responsible.\n",
    "### Answer\n",
    "\"\"\"\n",
    "\n",
    "# Generate answer from base model\n",
    "base_answer = generate_answer(base_model, tokenizer, prompt)\n",
    "\n",
    "# Generate answer from PEFT adapted model\n",
    "peft_answer = generate_answer(model_A, tokenizer, prompt)\n",
    "\n",
    "print(\"Base Model Answer:\", base_answer)\n",
    "print(\"PEFT Adapted Model Answer:\", peft_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
